{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/fixes.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_data = pd.read_csv('post_data/tweets_clustered.csv')\n",
    "cluster_dict = dict(zip(cluster_data.id.apply(str), cluster_data.cluster))\n",
    "user_dict = dict(zip(cluster_data.id.apply(str), cluster_data.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = pd.read_csv('post_data/cluster_locations.csv')\n",
    "\n",
    "cluster_numbers = sorted(set(cluster_data.cluster))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read posts from file\n",
    "\n",
    "posts = {x: [] for x in cluster_numbers}\n",
    "posts_by_user = {x: {} for x in cluster_numbers}\n",
    "stopWords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopWords.update(['love', 'day', 'like', 'good', 'time', 'today', 'night',\n",
    "                  'got', 'great', 'one', 'tonight', 'get'])\n",
    "\n",
    "with open('CSVs/instagram_data_20170825-155658.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "\n",
    "    for row in spamreader:\n",
    "        cluster = cluster_dict[row[0]]\n",
    "        username = user_dict[row[0]]\n",
    "        \n",
    "        untagPost = re.sub('@[\\w.-]+', '', row[2]).lower()\n",
    "        #words = []\n",
    "        for word in nltk.word_tokenize(untagPost):\n",
    "            if word not in stopWords and re.match('^[A-Za-z]+$', word) and len(word) > 2:\n",
    "                #words.append(word)\n",
    "                if username in posts_by_user[cluster]:\n",
    "                    posts_by_user[cluster][username].append(word)\n",
    "                else:\n",
    "                    posts_by_user[cluster][username] = [word]\n",
    "        #text = ' '.join(words)\n",
    "        #posts[cluster].append(text)\n",
    "\n",
    "for x in cluster_numbers:\n",
    "    locposts = posts_by_user[x]\n",
    "    for user in locposts.keys():\n",
    "        words = set(locposts[user])\n",
    "        text = ' '.join(words)\n",
    "        posts[x].append(text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # write to files\n",
    "# corpusdir = os.path.join('post_data', 'corpus')\n",
    "# corpus_files = []\n",
    "# for clustnum in posts.keys():\n",
    "#     outfile = os.path.join(corpusdir,\n",
    "#                            'instagram_cluster_' + str(clustnum) + '.txt')\n",
    "    \n",
    "#     with open(outfile, 'w') as f:\n",
    "#         for post in posts[cluster]:\n",
    "#             f.write(post)\n",
    "#     corpus_files.append(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([l.lower() for l in nltk.corpus.words.words()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')\n",
    "tfidf = TfidfVectorizer(min_df = 5, vocabulary = vocab)\n",
    "\n",
    "\n",
    "post_text_tfidf = [' '.join(posts[p]) for p in cluster_numbers]\n",
    "\n",
    "tfs = tfidf.fit_transform(post_text_tfidf)\n",
    "\n",
    "features = tfidf.get_feature_names()\n",
    "\n",
    "dense = tfs.todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basing code off of http://www.markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/\n",
    "\n",
    "topwords = {}\n",
    "for x in range(0, len(dense)):\n",
    "    citywords = []\n",
    "    cluster = cluster_numbers[x]\n",
    "    row = dense[x].tolist()[0]\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(row)), row) if pair[1] > 0]\n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "    for phrase, score in [(features[word_id], score) for (word_id, score) in sorted_phrase_scores][:10]:\n",
    "        citywords.append(phrase)\n",
    "    topwords[cluster] = citywords\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(timeout = 10)\n",
    "\n",
    "addressnames = []\n",
    "for c in cluster_numbers:\n",
    "    if c >= 0:\n",
    "        lat = clusters.iloc[c]['lat']\n",
    "        long = clusters.iloc[c]['long']\n",
    "        coordstr = str(lat) + ', ' + str(long)\n",
    "        location = geolocator.reverse(coordstr)\n",
    "        address = location.raw['address']\n",
    "        \n",
    "        addelem = []\n",
    "        if 'city' in address:\n",
    "            addelem.append(address['city'])\n",
    "        elif 'town' in address:\n",
    "            addelem.append(address['town'])\n",
    "        elif 'village' in address:\n",
    "            addelem.append(address['village'])\n",
    "        elif 'locality' in address:\n",
    "            addelem.append(address['locality'])\n",
    "        elif 'suburb' in address:\n",
    "            addelem.append(address['suburb'])\n",
    "                            \n",
    "        if 'state' in address:\n",
    "            addelem.append(address['state'])\n",
    "        if 'country' in address:\n",
    "            addelem.append(address['country'])\n",
    "        \n",
    "        addressnames.append(', '.join(addelem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnums = [c for c in cluster_numbers if c >= 0]\n",
    "\n",
    "topwords_by_cluster = pd.DataFrame({ 'clustnum' : cnums,\n",
    "             'lat' : [clusters.iloc[x]['lat'] for x in cnums],\n",
    "             'long' : [clusters.iloc[x]['long'] for x in cnums],\n",
    "             'words' : [' '.join(topwords[x]) for x in cnums],\n",
    "             'address' : addressnames})\n",
    "topwords_by_cluster.to_csv('post_data/top_words.csv', index = False, sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
